{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6174d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270bcc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Who directed the movie 'Titanic'?</td>\n",
       "      <td>JamesCameron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Which superhero is also known as the Dark Knight?</td>\n",
       "      <td>Batman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>What is the capital of Brazil?</td>\n",
       "      <td>Brasilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Which fruit is known as the king of fruits?</td>\n",
       "      <td>Mango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Which country is known for the Eiffel Tower?</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question        answer\n",
       "0                      What is the capital of France?         Paris\n",
       "1                     What is the capital of Germany?        Berlin\n",
       "2                  Who wrote 'To Kill a Mockingbird'?    Harper-Lee\n",
       "3     What is the largest planet in our solar system?       Jupiter\n",
       "4      What is the boiling point of water in Celsius?           100\n",
       "..                                                ...           ...\n",
       "85                  Who directed the movie 'Titanic'?  JamesCameron\n",
       "86  Which superhero is also known as the Dark Knight?        Batman\n",
       "87                     What is the capital of Brazil?      Brasilia\n",
       "88        Which fruit is known as the king of fruits?         Mango\n",
       "89       Which country is known for the Eiffel Tower?        France\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"100_Unique_QA_Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9542eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\",'')\n",
    "    text = text.replace(\"'\",'')\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9bdbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who', 'wrote', 'romeo', 'and', 'juliet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"Who wrote 'Romeo and Juliet'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3a8c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocabulary\n",
    "vocab = {'<UNK>':0}\n",
    "vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b2a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(row):\n",
    "    tokenized_question = tokenize(row['question'])\n",
    "    tokenized_answer = tokenize(row['answer'])\n",
    "    merged_tokens = tokenized_question + tokenized_answer\n",
    "    # print(merged_tokens)\n",
    "    for token in merged_tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d26d270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57af20f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(build_vocab,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c303005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'what': 1,\n",
       " 'is': 2,\n",
       " 'the': 3,\n",
       " 'capital': 4,\n",
       " 'of': 5,\n",
       " 'france': 6,\n",
       " 'paris': 7,\n",
       " 'germany': 8,\n",
       " 'berlin': 9,\n",
       " 'who': 10,\n",
       " 'wrote': 11,\n",
       " 'to': 12,\n",
       " 'kill': 13,\n",
       " 'a': 14,\n",
       " 'mockingbird': 15,\n",
       " 'harper-lee': 16,\n",
       " 'largest': 17,\n",
       " 'planet': 18,\n",
       " 'in': 19,\n",
       " 'our': 20,\n",
       " 'solar': 21,\n",
       " 'system': 22,\n",
       " 'jupiter': 23,\n",
       " 'boiling': 24,\n",
       " 'point': 25,\n",
       " 'water': 26,\n",
       " 'celsius': 27,\n",
       " '100': 28,\n",
       " 'painted': 29,\n",
       " 'mona': 30,\n",
       " 'lisa': 31,\n",
       " 'leonardo-da-vinci': 32,\n",
       " 'square': 33,\n",
       " 'root': 34,\n",
       " '64': 35,\n",
       " '8': 36,\n",
       " 'chemical': 37,\n",
       " 'symbol': 38,\n",
       " 'for': 39,\n",
       " 'gold': 40,\n",
       " 'au': 41,\n",
       " 'which': 42,\n",
       " 'year': 43,\n",
       " 'did': 44,\n",
       " 'world': 45,\n",
       " 'war': 46,\n",
       " 'ii': 47,\n",
       " 'end': 48,\n",
       " '1945': 49,\n",
       " 'longest': 50,\n",
       " 'river': 51,\n",
       " 'nile': 52,\n",
       " 'japan': 53,\n",
       " 'tokyo': 54,\n",
       " 'developed': 55,\n",
       " 'theory': 56,\n",
       " 'relativity': 57,\n",
       " 'albert-einstein': 58,\n",
       " 'freezing': 59,\n",
       " 'fahrenheit': 60,\n",
       " '32': 61,\n",
       " 'known': 62,\n",
       " 'as': 63,\n",
       " 'red': 64,\n",
       " 'mars': 65,\n",
       " 'author': 66,\n",
       " '1984': 67,\n",
       " 'george-orwell': 68,\n",
       " 'currency': 69,\n",
       " 'united': 70,\n",
       " 'kingdom': 71,\n",
       " 'pound': 72,\n",
       " 'india': 73,\n",
       " 'delhi': 74,\n",
       " 'discovered': 75,\n",
       " 'gravity': 76,\n",
       " 'newton': 77,\n",
       " 'how': 78,\n",
       " 'many': 79,\n",
       " 'continents': 80,\n",
       " 'are': 81,\n",
       " 'there': 82,\n",
       " 'on': 83,\n",
       " 'earth': 84,\n",
       " '7': 85,\n",
       " 'gas': 86,\n",
       " 'do': 87,\n",
       " 'plants': 88,\n",
       " 'use': 89,\n",
       " 'photosynthesis': 90,\n",
       " 'co2': 91,\n",
       " 'smallest': 92,\n",
       " 'prime': 93,\n",
       " 'number': 94,\n",
       " '2': 95,\n",
       " 'invented': 96,\n",
       " 'telephone': 97,\n",
       " 'alexander-graham-bell': 98,\n",
       " 'australia': 99,\n",
       " 'canberra': 100,\n",
       " 'ocean': 101,\n",
       " 'pacific-ocean': 102,\n",
       " 'speed': 103,\n",
       " 'light': 104,\n",
       " 'vacuum': 105,\n",
       " '299,792,458m/s': 106,\n",
       " 'language': 107,\n",
       " 'spoken': 108,\n",
       " 'brazil': 109,\n",
       " 'portuguese': 110,\n",
       " 'penicillin': 111,\n",
       " 'alexander-fleming': 112,\n",
       " 'canada': 113,\n",
       " 'ottawa': 114,\n",
       " 'mammal': 115,\n",
       " 'whale': 116,\n",
       " 'element': 117,\n",
       " 'has': 118,\n",
       " 'atomic': 119,\n",
       " '1': 120,\n",
       " 'hydrogen': 121,\n",
       " 'tallest': 122,\n",
       " 'mountain': 123,\n",
       " 'everest': 124,\n",
       " 'city': 125,\n",
       " 'big': 126,\n",
       " 'apple': 127,\n",
       " 'newyork': 128,\n",
       " 'planets': 129,\n",
       " 'starry': 130,\n",
       " 'night': 131,\n",
       " 'vangogh': 132,\n",
       " 'formula': 133,\n",
       " 'h2o': 134,\n",
       " 'italy': 135,\n",
       " 'rome': 136,\n",
       " 'country': 137,\n",
       " 'famous': 138,\n",
       " 'sushi': 139,\n",
       " 'was': 140,\n",
       " 'first': 141,\n",
       " 'person': 142,\n",
       " 'step': 143,\n",
       " 'moon': 144,\n",
       " 'armstrong': 145,\n",
       " 'main': 146,\n",
       " 'ingredient': 147,\n",
       " 'guacamole': 148,\n",
       " 'avocado': 149,\n",
       " 'sides': 150,\n",
       " 'does': 151,\n",
       " 'hexagon': 152,\n",
       " 'have': 153,\n",
       " '6': 154,\n",
       " 'china': 155,\n",
       " 'yuan': 156,\n",
       " 'pride': 157,\n",
       " 'and': 158,\n",
       " 'prejudice': 159,\n",
       " 'jane-austen': 160,\n",
       " 'iron': 161,\n",
       " 'fe': 162,\n",
       " 'hardest': 163,\n",
       " 'natural': 164,\n",
       " 'substance': 165,\n",
       " 'diamond': 166,\n",
       " 'continent': 167,\n",
       " 'by': 168,\n",
       " 'area': 169,\n",
       " 'asia': 170,\n",
       " 'president': 171,\n",
       " 'states': 172,\n",
       " 'george-washington': 173,\n",
       " 'bird': 174,\n",
       " 'its': 175,\n",
       " 'ability': 176,\n",
       " 'mimic': 177,\n",
       " 'sounds': 178,\n",
       " 'parrot': 179,\n",
       " 'longest-running': 180,\n",
       " 'animated': 181,\n",
       " 'tv': 182,\n",
       " 'show': 183,\n",
       " 'simpsons': 184,\n",
       " 'vaticancity': 185,\n",
       " 'most': 186,\n",
       " 'moons': 187,\n",
       " 'saturn': 188,\n",
       " 'romeo': 189,\n",
       " 'juliet': 190,\n",
       " 'shakespeare': 191,\n",
       " 'earths': 192,\n",
       " 'atmosphere': 193,\n",
       " 'nitrogen': 194,\n",
       " 'bones': 195,\n",
       " 'adult': 196,\n",
       " 'human': 197,\n",
       " 'body': 198,\n",
       " '206': 199,\n",
       " 'metal': 200,\n",
       " 'liquid': 201,\n",
       " 'at': 202,\n",
       " 'room': 203,\n",
       " 'temperature': 204,\n",
       " 'mercury': 205,\n",
       " 'russia': 206,\n",
       " 'moscow': 207,\n",
       " 'electricity': 208,\n",
       " 'benjamin-franklin': 209,\n",
       " 'second-largest': 210,\n",
       " 'land': 211,\n",
       " 'color': 212,\n",
       " 'ripe': 213,\n",
       " 'banana': 214,\n",
       " 'yellow': 215,\n",
       " 'month': 216,\n",
       " '28': 217,\n",
       " 'days': 218,\n",
       " 'common': 219,\n",
       " 'february': 220,\n",
       " 'study': 221,\n",
       " 'living': 222,\n",
       " 'organisms': 223,\n",
       " 'called': 224,\n",
       " 'biology': 225,\n",
       " 'home': 226,\n",
       " 'great': 227,\n",
       " 'wall': 228,\n",
       " 'bees': 229,\n",
       " 'collect': 230,\n",
       " 'from': 231,\n",
       " 'flowers': 232,\n",
       " 'nectar': 233,\n",
       " 'opposite': 234,\n",
       " 'day': 235,\n",
       " 'south': 236,\n",
       " 'korea': 237,\n",
       " 'seoul': 238,\n",
       " 'bulb': 239,\n",
       " 'edison': 240,\n",
       " 'humans': 241,\n",
       " 'breathe': 242,\n",
       " 'survival': 243,\n",
       " 'oxygen': 244,\n",
       " '144': 245,\n",
       " '12': 246,\n",
       " 'pyramids': 247,\n",
       " 'giza': 248,\n",
       " 'egypt': 249,\n",
       " 'sea': 250,\n",
       " 'creature': 251,\n",
       " 'eight': 252,\n",
       " 'arms': 253,\n",
       " 'octopus': 254,\n",
       " 'holiday': 255,\n",
       " 'celebrated': 256,\n",
       " 'december': 257,\n",
       " '25': 258,\n",
       " 'christmas': 259,\n",
       " 'yen': 260,\n",
       " 'legs': 261,\n",
       " 'spider': 262,\n",
       " 'sport': 263,\n",
       " 'uses': 264,\n",
       " 'net,': 265,\n",
       " 'ball,': 266,\n",
       " 'hoop': 267,\n",
       " 'basketball': 268,\n",
       " 'kangaroos': 269,\n",
       " 'female': 270,\n",
       " 'minister': 271,\n",
       " 'uk': 272,\n",
       " 'margaretthatcher': 273,\n",
       " 'fastest': 274,\n",
       " 'animal': 275,\n",
       " 'cheetah': 276,\n",
       " 'periodic': 277,\n",
       " 'table': 278,\n",
       " 'spain': 279,\n",
       " 'madrid': 280,\n",
       " 'closest': 281,\n",
       " 'sun': 282,\n",
       " 'father': 283,\n",
       " 'computers': 284,\n",
       " 'charlesbabbage': 285,\n",
       " 'mexico': 286,\n",
       " 'mexicocity': 287,\n",
       " 'colors': 288,\n",
       " 'rainbow': 289,\n",
       " 'musical': 290,\n",
       " 'instrument': 291,\n",
       " 'black': 292,\n",
       " 'white': 293,\n",
       " 'keys': 294,\n",
       " 'piano': 295,\n",
       " 'americas': 296,\n",
       " '1492': 297,\n",
       " 'christophercolumbus': 298,\n",
       " 'disney': 299,\n",
       " 'character': 300,\n",
       " 'long': 301,\n",
       " 'nose': 302,\n",
       " 'grows': 303,\n",
       " 'it': 304,\n",
       " 'when': 305,\n",
       " 'lying': 306,\n",
       " 'pinocchio': 307,\n",
       " 'directed': 308,\n",
       " 'movie': 309,\n",
       " 'titanic': 310,\n",
       " 'jamescameron': 311,\n",
       " 'superhero': 312,\n",
       " 'also': 313,\n",
       " 'dark': 314,\n",
       " 'knight': 315,\n",
       " 'batman': 316,\n",
       " 'brasilia': 317,\n",
       " 'fruit': 318,\n",
       " 'king': 319,\n",
       " 'fruits': 320,\n",
       " 'mango': 321,\n",
       " 'eiffel': 322,\n",
       " 'tower': 323}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "844deec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf87c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert words to num indices\n",
    "def text_to_indices(text,vocab):\n",
    "    indexed_text = []\n",
    "    for token in tokenize(text):\n",
    "        if token in vocab:\n",
    "            indexed_text.append(vocab[token])\n",
    "        else:\n",
    "            indexed_text.append(vocab['<UNK>'])\n",
    "    return indexed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c4e35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices(\"What is campusx?\",vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e57ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "454715ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self,df,vocab):\n",
    "        self.df = df \n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        numerical_question = text_to_indices(self.df.iloc[index]['question'],self.vocab)\n",
    "        numerical_answer = text_to_indices(self.df.iloc[index]['answer'],self.vocab)\n",
    "        return torch.tensor(numerical_question),torch.tensor(numerical_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90aeb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(df,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "811ac1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e924d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "#SINCE batch_size = 1 no need to do padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429634a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
      "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
      "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
      "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
      "tensor([[10, 75, 76]]) tensor([[77]])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n"
     ]
    }
   ],
   "source": [
    "for question,answer in dataloader:\n",
    "    print(question,answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6d92601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn architecture\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding_dim=50) #converts (batch_size,seq_len) to (batch_size,seq_len,emdedding_dim(50))\n",
    "        self.rnn = nn.RNN(50,64,batch_first=True) # converts (batch_size,seq_len,emdedding_dim) to (batch_size,seq_len,#hidden_state(64)) as entire hidden state output and (batch_size,1,#hidden_state(64)) as final output\n",
    "        #input_size=50, hidden_size=64\n",
    "        #by default RNN expects input of shape (seq_len, batch_size, input_size)\n",
    "        #but in our data it is (batch_size,seq_len,input_size) so check batch_first=True)\n",
    "        #returns a tuble with hidden states(including output) and final output \n",
    "        #since nn.RNN returns two values we cant use Sequential container\n",
    "        self.fc = nn.Linear(64,vocab_size)\n",
    "        #accepts input in form [1,64](even if [64,] is passed)\n",
    "\n",
    "    def forward(self,question):\n",
    "        embedded_question = self.embedding(question)\n",
    "        hidden,final = self.rnn(embedded_question)\n",
    "        output = self.fc(final.squeeze(0))\n",
    "\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915434c5",
   "metadata": {},
   "source": [
    "Test Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deed715d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e480912",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = torch.tensor([[ 42, 137,2,138,39,175,269]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b25e87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(324,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0a1a194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3929, -0.7555, -0.3856, -0.2767,  0.6938,  2.6430, -2.4449,  0.7403,\n",
       "         2.6030, -0.9837, -1.4852, -1.7795, -1.2435,  1.1410,  0.0836,  0.6653,\n",
       "         0.1743, -1.4229, -0.5034,  0.8689,  0.2606, -2.2237,  0.9127,  0.2160,\n",
       "        -0.1072,  0.7021,  0.6581,  0.3915, -0.0606,  0.4988, -0.6211, -0.3967,\n",
       "        -0.9004,  0.0266,  0.7802, -0.1563,  2.6160, -2.9990, -0.4288,  0.0816,\n",
       "         0.3562,  0.3013,  0.7703,  2.8769, -0.8720, -0.9588, -0.8056,  0.6607,\n",
       "        -0.4894, -1.0140], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11388527",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embed = embedding(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6713a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.4084e-02,  1.3554e+00,  9.8286e-01,  2.2110e-01, -8.4011e-02,\n",
       "           4.5728e-02, -1.2521e+00,  3.9102e-01,  1.1644e+00, -2.4370e-01,\n",
       "           1.0514e+00,  3.0279e-01,  3.4027e-01,  2.5432e-01,  5.6675e-01,\n",
       "          -8.6733e-01,  2.4489e+00,  2.2599e-01,  1.9926e+00,  9.0528e-01,\n",
       "          -1.3234e+00,  1.0407e+00, -1.6158e+00,  1.9492e+00,  5.5116e-01,\n",
       "           3.7522e-01, -7.1691e-02,  2.2426e-01,  5.5321e-01, -2.7482e+00,\n",
       "          -1.8221e+00,  1.0434e+00,  1.0565e+00,  1.2589e+00, -5.2421e-01,\n",
       "           8.1276e-01, -2.4360e+00, -1.9424e+00,  6.4586e-01,  3.9437e-01,\n",
       "          -1.0603e+00,  9.3096e-03, -3.2104e-01, -1.9822e+00, -1.3030e-02,\n",
       "           4.9360e-01, -2.3385e-01,  9.0409e-01,  1.6889e-01,  8.1372e-01],\n",
       "         [-2.1467e-01, -1.3902e+00,  8.4556e-01,  7.8303e-01, -7.1867e-01,\n",
       "          -8.8965e-01,  1.5101e+00,  7.2903e-01,  1.0124e+00,  7.4131e-01,\n",
       "           6.6974e-01,  2.2667e-01, -1.2132e+00, -2.1732e-02,  4.1930e-02,\n",
       "          -1.4682e+00, -8.4889e-02,  1.1849e+00,  2.2994e-01,  2.0197e+00,\n",
       "          -8.2137e-01, -6.4554e-01,  1.5716e+00, -1.9782e+00, -2.9166e-01,\n",
       "           1.6237e-01,  1.1574e+00,  2.8879e-01,  8.0652e-01,  3.7009e-01,\n",
       "           7.9848e-01, -3.0336e-01,  9.8585e-01, -3.2325e-01, -2.0585e+00,\n",
       "           2.1670e+00,  6.7775e-02, -1.7628e+00, -5.7365e-02,  1.2535e+00,\n",
       "           5.5530e-01, -9.5847e-01, -7.3911e-01,  6.2778e-02,  1.0838e+00,\n",
       "           4.5821e-01, -5.8269e-01, -1.4586e+00,  1.1504e+00, -3.5627e-01],\n",
       "         [-1.0091e-01, -8.1554e-01,  3.6560e-01, -1.2989e+00, -6.4812e-02,\n",
       "           3.7441e-02, -2.2430e-01, -8.9312e-01,  1.4473e+00, -6.1478e-01,\n",
       "          -9.1778e-01,  1.0761e+00, -1.0886e+00, -1.5323e+00, -1.1512e+00,\n",
       "          -1.4871e-02, -1.5325e+00,  1.7710e-01,  3.6729e-01, -1.1406e+00,\n",
       "          -2.0264e-01, -1.5092e+00, -3.3141e-01, -5.8095e-01,  1.4589e+00,\n",
       "           6.9828e-01,  3.2190e-01, -1.3349e-02,  1.7870e+00,  6.9656e-01,\n",
       "          -8.3450e-01,  5.0257e-01,  6.4179e-01,  5.4207e-01,  3.2325e-01,\n",
       "          -1.8079e+00, -5.4679e-01,  1.8043e+00,  1.0522e-03,  6.0609e-01,\n",
       "          -9.3956e-01, -3.9411e-01,  5.2885e-01, -4.2166e-01, -6.5197e-01,\n",
       "          -7.7813e-01, -1.2835e-01, -3.0222e-01,  4.0914e-02, -5.2119e-01],\n",
       "         [ 3.1261e-01,  1.7768e-01, -1.9235e-01,  5.0258e-01,  2.8808e-01,\n",
       "           3.0864e-01, -1.1664e+00, -1.0481e+00,  1.4935e+00, -3.8132e-01,\n",
       "          -5.7740e-02, -5.3518e-01,  1.1815e+00, -2.5291e+00, -1.0524e+00,\n",
       "           1.6548e-01, -3.7700e-01,  1.1729e+00, -1.1688e+00,  4.5850e-01,\n",
       "           2.2716e+00,  1.7177e+00, -3.3764e-01,  1.2270e+00,  1.9071e+00,\n",
       "           6.7062e-01,  7.1040e-01, -1.0555e+00,  9.5617e-01,  3.4483e-01,\n",
       "           9.4659e-01, -1.1107e+00,  1.1717e+00, -1.3278e+00,  1.1782e+00,\n",
       "          -8.3038e-01, -4.7602e-01,  8.9659e-02, -6.0926e-01,  4.8035e-02,\n",
       "           4.4242e-01, -3.0964e-01,  1.3753e+00, -1.3073e+00,  2.1110e-01,\n",
       "          -1.5411e-01,  1.2616e+00, -2.2689e-01,  6.0277e-01,  3.0341e-01],\n",
       "         [-2.5379e-01, -4.7274e-01,  1.2132e+00, -7.7422e-01,  1.1415e+00,\n",
       "          -1.8614e+00,  3.6831e-01,  1.9045e+00, -7.8816e-01, -1.7245e+00,\n",
       "          -7.1029e-01, -1.1964e+00,  2.9839e-01, -1.1449e+00, -4.2466e-01,\n",
       "          -1.1164e+00,  8.4569e-01, -6.4672e-01,  1.5930e-01,  3.3596e-01,\n",
       "           1.4497e+00, -1.0651e-01, -8.6146e-01, -1.1738e-01, -7.1238e-01,\n",
       "           4.3188e-01, -6.8372e-01, -1.0688e+00,  5.2648e-01, -7.9832e-01,\n",
       "          -3.0681e-02,  4.4873e-01, -8.6349e-01,  1.3989e+00,  7.2605e-01,\n",
       "          -1.5672e-01, -2.5976e+00,  1.3100e-01, -5.0036e-01,  4.1945e-01,\n",
       "          -5.6015e-02, -2.0790e+00,  1.5093e-01, -3.9775e-01,  6.6268e-01,\n",
       "          -1.8919e+00, -2.2508e-01, -1.6997e+00, -6.7684e-01,  5.4891e-01],\n",
       "         [ 1.9592e-01,  2.6186e+00,  1.6964e+00, -1.0567e+00, -1.3064e+00,\n",
       "          -5.3494e-01, -3.1487e-01,  8.6438e-03, -1.4812e+00, -1.4991e+00,\n",
       "           1.0204e+00, -8.4040e-01, -1.0129e+00,  1.1714e+00, -3.8373e-01,\n",
       "          -3.2859e-01, -5.7782e-01, -1.9275e+00, -1.6588e+00,  8.3280e-01,\n",
       "           1.3905e+00, -5.5368e-01, -8.4084e-01,  3.5849e-01, -4.2382e-02,\n",
       "           2.0743e-01,  1.3411e+00, -1.2786e+00, -5.6059e-01, -4.8543e-01,\n",
       "          -1.8538e+00, -5.2002e-01, -7.5681e-01,  5.9773e-01, -9.9013e-02,\n",
       "          -5.9751e-01, -4.6303e-02,  1.9939e+00,  6.3536e-01, -1.6446e-01,\n",
       "          -6.2079e-01, -1.2938e-01,  3.5936e-01, -8.4049e-01, -4.2254e-01,\n",
       "          -6.3424e-01, -2.0493e+00, -2.0654e+00,  8.1341e-01,  1.4596e+00],\n",
       "         [-9.8099e-01, -3.1005e+00, -7.6684e-01, -1.4322e+00,  2.7059e+00,\n",
       "           1.5169e+00, -1.0398e+00,  7.7426e-02,  1.8975e+00,  8.1996e-01,\n",
       "           1.1633e+00, -5.7254e-01,  3.5587e-02,  9.1000e-01,  1.6525e+00,\n",
       "          -1.5127e+00, -1.7789e+00, -1.4192e+00, -1.0585e+00, -2.6971e-02,\n",
       "          -2.0982e-01,  8.4727e-01,  4.4732e-02, -1.3429e+00,  1.8867e-01,\n",
       "          -2.6740e+00, -6.1156e-01,  3.7559e-01,  2.9657e-01, -1.3586e+00,\n",
       "           1.4070e+00, -4.7845e-01, -1.7564e-01,  6.7079e-02,  3.3157e+00,\n",
       "           1.8218e-01,  8.2246e-01,  5.8326e-01,  1.4539e+00, -4.0000e-01,\n",
       "          -1.2585e+00, -1.8557e+00, -1.7820e+00,  6.6787e-01, -6.8705e-01,\n",
       "          -8.4046e-01,  1.8303e+00, -4.8964e-01, -3.8910e-01,  2.0704e-01]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b54358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 50])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(50,64,batch_first=True) #input_size=50, hidden_size=64\n",
    "#by default RNN expects input of shape (seq_len, batch_size, input_size)\n",
    "#but in our data it is (batch_size,seq_len,input_size) so check batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first,second =rnn(test_embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c50b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ac75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71079f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1895, -0.6207, -0.0844,  0.1979, -0.5990, -0.2964, -0.7810,\n",
       "          -0.7218,  0.5224,  0.8418, -0.6870,  0.8018, -0.5941, -0.5047,\n",
       "          -0.5172, -0.0828,  0.4543,  0.3174,  0.2996,  0.7059,  0.2459,\n",
       "          -0.7843,  0.5197,  0.0102, -0.2185,  0.5318, -0.2488,  0.4722,\n",
       "          -0.0294,  0.0193, -0.6658,  0.3550, -0.6983,  0.3227, -0.0882,\n",
       "           0.8325,  0.0640,  0.0467, -0.3258,  0.5134, -0.6654,  0.0277,\n",
       "           0.2671,  0.1848,  0.1400, -0.4369,  0.3591,  0.0673,  0.3006,\n",
       "           0.1492,  0.3928, -0.1928, -0.6377, -0.8901,  0.2189,  0.9212,\n",
       "           0.3947,  0.5878, -0.0632,  0.1532, -0.4839,  0.8729, -0.3097,\n",
       "           0.0690]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df91e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second.squeeze(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa849ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss : 0.11223381703926458\n",
      "Epoch: 2, Loss : 0.09845897427035702\n",
      "Epoch: 3, Loss : 0.08685827950636546\n",
      "Epoch: 4, Loss : 0.0775203652265999\n",
      "Epoch: 5, Loss : 0.06947166745861372\n",
      "Epoch: 6, Loss : 0.06289379267642896\n",
      "Epoch: 7, Loss : 0.056638387776911256\n",
      "Epoch: 8, Loss : 0.05150830816063616\n",
      "Epoch: 9, Loss : 0.04696841357896726\n",
      "Epoch: 10, Loss : 0.04304931296242608\n",
      "Epoch: 11, Loss : 0.03956645568832755\n",
      "Epoch: 12, Loss : 0.036360717337164616\n",
      "Epoch: 13, Loss : 0.033604884965138304\n",
      "Epoch: 14, Loss : 0.031043976183152862\n",
      "Epoch: 15, Loss : 0.028827987155980533\n",
      "Epoch: 16, Loss : 0.026724991264442603\n",
      "Epoch: 17, Loss : 0.024923955524961152\n",
      "Epoch: 18, Loss : 0.023213663614458507\n",
      "Epoch: 19, Loss : 0.021677443705913093\n",
      "Epoch: 20, Loss : 0.020250137471076516\n"
     ]
    }
   ],
   "source": [
    "#training loop \n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for question,answer in dataloader:\n",
    "        #forward pass\n",
    "        output = model(question)\n",
    "        #loss \n",
    "        loss = criterion(output,answer[0])\n",
    "        #accepts output in shape (batch_size,num_classes) internally used softmax to get the out_class\n",
    "        #and answer in shape (batch_size)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        #update\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "    print(f\"Epoch: {epoch+1}, Loss : {total_loss/len(dataloader)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55987d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "def predict(model,question,threshold=0.5):\n",
    "    #convert questions to numbers\n",
    "    numerical_question = text_to_indices(question,vocab)\n",
    "    #tensor\n",
    "    question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "    #embedding layer accepts input in (batch_size,seq_len) \n",
    "    #send to model\n",
    "    output = model(question_tensor)\n",
    "\n",
    "    #convert logits to probs\n",
    "    probs = torch.nn.functional.softmax(output,dim=1)\n",
    "\n",
    "    #find index of max prob\n",
    "    value,index = torch.max(probs,dim =1)\n",
    "\n",
    "    if value < threshold:\n",
    "        print(\"I don't know\")\n",
    "\n",
    "    print(list(vocab.keys())[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336bf241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\n"
     ]
    }
   ],
   "source": [
    "predict(model,\"What is the capital of france\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
