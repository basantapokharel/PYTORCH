{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc006fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517bf6d",
   "metadata": {},
   "source": [
    "Firstly we'll see the inbuilt implementation of cross entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6758154",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41849e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: tensor(0.4449)\n"
     ]
    }
   ],
   "source": [
    "# Example batch of 3 samples and 3 classes\n",
    "logits = torch.tensor([\n",
    "    [2.0, 0.5, 1.0],   # sample 0\n",
    "    [0.2, 1.5, 0.3],   # sample 1\n",
    "    [1.0, 2.0, 0.1]    # sample 2\n",
    "])\n",
    "\n",
    "# Correct classes for each sample\n",
    "targets = torch.tensor([0, 1, 1], dtype=torch.long)\n",
    "\n",
    "# Compute loss\n",
    "loss = loss(logits, targets)\n",
    "print(\"Cross Entropy Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b8827",
   "metadata": {},
   "source": [
    "Now we will see the implementation of it from scratch to get the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ff2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([\n",
    "    [2.0, 0.5, 1.0],   # sample 0\n",
    "    [0.2, 1.5, 0.3],   # sample 1\n",
    "    [1.0, 2.0, 0.1]    # sample 2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90571a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([0, 1, 1], dtype=torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e498b46",
   "metadata": {},
   "source": [
    "Now we need the max element from each batch and subtract the batch with that number "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7280ec",
   "metadata": {},
   "source": [
    "for that we need the max of each batch while keeping the dimension as it is so subtraction will be as we desire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4b69120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[2.0000],\n",
       "        [1.5000],\n",
       "        [2.0000]]),\n",
       "indices=tensor([[0],\n",
       "        [1],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_elements = logits.max(dim = 1, keepdim=True)\n",
    "max_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f7983d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000],\n",
       "        [1.5000],\n",
       "        [2.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_elements = max_elements.values\n",
    "max_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ea21d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.5000, -1.0000],\n",
       "        [-1.3000,  0.0000, -1.2000],\n",
       "        [-1.0000,  0.0000, -1.9000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits - max_elements\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fb611",
   "metadata": {},
   "source": [
    "This is the simplified logits "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739de46f",
   "metadata": {},
   "source": [
    "Now we need to find log(softmax(logits)) using modified formula :"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e59e9219",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c815b",
   "metadata": {},
   "source": [
    "where this gives 3*3 matrix for each batch and each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3caf2",
   "metadata": {},
   "source": [
    "1) first do exponential to each element in logits \n",
    "2) find batch wise sum of each term ie summation(e^zk) preserving the dimension as we need to perform subtraction batch wise from logits(zj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab256a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4644],\n",
       "        [0.4534],\n",
       "        [0.4170]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_sum_exp = torch.log(torch.exp(logits).sum(dim = 1 , keepdim=True))\n",
    "log_sum_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c4cc4",
   "metadata": {},
   "source": [
    "now subtract from logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c9ff78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4644, -1.9644, -1.4644],\n",
       "        [-1.7534, -0.4534, -1.6534],\n",
       "        [-1.4170, -0.4170, -2.3170]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = logits - log_sum_exp\n",
    "log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee7ac7",
   "metadata": {},
   "source": [
    "This gave the final log(softmax(logits)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb196f9f",
   "metadata": {},
   "source": [
    "To get the actual loss follow: \n",
    "1) extract the actual class probability from each batch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149469a",
   "metadata": {},
   "source": [
    "for step 1 we'll use advanced indexing in tensor (also available in numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079f4e7",
   "metadata": {},
   "source": [
    "Its a way to extract required elements from tensor by giving indexes from tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b0034",
   "metadata": {},
   "source": [
    "in our case actual label is torch.tensor([0, 1, 1]) ie from first row first element , from second row 2nd element and from third row also 2nd element "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88974be",
   "metadata": {},
   "source": [
    "so advanced indexing helps us to get the required elements in one go here a tensor takes two arguments ie in first tensor which rows and in second tensor which columns elements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5a283",
   "metadata": {},
   "source": [
    "for rows we need all rows ie logits.shape[0] = 3 in our case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc3e71",
   "metadata": {},
   "source": [
    "lets define no of rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33772031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = logits.shape[0] \n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60ab4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = torch.arange(N)\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff1f52",
   "metadata": {},
   "source": [
    "now for column we need exactly the column specified by final label ie 0,1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c24ae225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4644, -0.4534, -0.4170])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_loss_in_batch = log_probs[rows,targets]\n",
    "required_loss_in_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374b085",
   "metadata": {},
   "source": [
    "This is the loss for each batch now we will apply mean operation to return final loss also add negative sign in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beb610ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4449)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -required_loss_in_batch.mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07f881",
   "metadata": {},
   "source": [
    "This is the exact same loss we got by inbuilt implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3097e",
   "metadata": {},
   "source": [
    "Now to sum up in the function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3beb67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_from_scratch(logits,targets):\n",
    "    # logits : (N,C) ie (batch size , no of classes)\n",
    "    # targets : (N,) long\n",
    "\n",
    "    # 1) For numerical stability \n",
    "    logits = logits - logits.max(dim=1,keepdim=True).values #(N,c)\n",
    "\n",
    "    #2) Log(softmax(logits))\n",
    "    log_sum_exp = torch.log(torch.exp(logits).sum(dim = 1,keepdim=True)) #(N,1)\n",
    "    log_probs = logits - log_sum_exp #(N,c)\n",
    "\n",
    "    #3) Indexing \n",
    "    N = logits.shape[0]\n",
    "    loss = -log_probs[torch.arange(N),targets].mean()\n",
    "\n",
    "    return loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9b8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: tensor(0.4449)\n"
     ]
    }
   ],
   "source": [
    "# Example batch of 3 samples and 3 classes\n",
    "logits = torch.tensor([\n",
    "    [2.0, 0.5, 1.0],   # sample 0\n",
    "    [0.2, 1.5, 0.3],   # sample 1\n",
    "    [1.0, 2.0, 0.1]    # sample 2\n",
    "])\n",
    "\n",
    "# Correct classes for each sample\n",
    "targets = torch.tensor([0, 1, 1], dtype=torch.int)\n",
    "\n",
    "# Compute loss\n",
    "loss = cross_entropy_from_scratch(logits, targets)\n",
    "print(\"Cross Entropy Loss:\", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
